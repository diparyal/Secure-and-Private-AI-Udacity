{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural networks with PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pKu2vI-plc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8CvSzPBsVSj",
        "colab_type": "code",
        "outputId": "81fc4d4f-1373-40e8-f15c-9bfe71f6c446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "from torchvision import datasets,transforms\n",
        "\n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)),])\n",
        "trainset=datasets.MNIST(\"~/.pytorch/MNIST_data/\",download=True,train=True,transform=transform)\n",
        "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20545648.50it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 316654.08it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5496748.32it/s]                           \n",
            "8192it [00:00, 130184.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IXF_VyitTOR",
        "colab_type": "code",
        "outputId": "6a1004da-c577-40be-926f-23818d43a8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "dataiter=iter(trainloader)\n",
        "images,labels=dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQsMNHKryjN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbxPmu44yxW_",
        "colab_type": "code",
        "outputId": "df8ceb94-7b9b-4d86-ff0a-600b8f8ff11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(),cmap=\"Greys_r\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f64b8e4ada0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn6qYL4X2tYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input=images.view(images.shape[0],-1)\n",
        "n_input=784\n",
        "n_hidden=256\n",
        "n_output=10\n",
        "W1=torch.randn(n_input,n_hidden)\n",
        "W2=torch.randn(n_hidden,n_output)\n",
        "B1=torch.randn(n_hidden)   #B1=torch.randn(1,n_hidden) not used as input is torch.Size([64, 1, 28, 28]) dimension\n",
        "B2=torch.randn(n_output)  #B2=torch.randn((1,n_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9p-Uy-x3FG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OVa8DtV2N0",
        "colab_type": "code",
        "outputId": "bba5a427-8ce4-455f-8e23-0966a69d3256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "torch.mm(input,W1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-33.2258,  -2.8003, -19.4740,  ..., -28.4807, -25.8809,  15.7613],\n",
              "        [ -8.4260,  -4.8786, -40.6170,  ..., -36.2042,   1.4699,   7.5717],\n",
              "        [-43.1829, -36.0819,  -0.2039,  ...,   7.2466, -38.2613,  10.4155],\n",
              "        ...,\n",
              "        [-23.8439, -25.0020, -34.8564,  ..., -15.0687, -37.0935,  21.3565],\n",
              "        [-67.1674, -37.1210, -25.6966,  ..., -19.4707, -48.4050,  -7.1964],\n",
              "        [-24.1049, -18.5074,  -6.3510,  ..., -11.3148, -34.0011,  35.0561]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s4Y0I2_V4t1",
        "colab_type": "code",
        "outputId": "9351d106-23c7-4f25-deb0-9fb55364d5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "torch.mm(input,W1)+B1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-33.1218,  -1.8445, -20.6608,  ..., -28.6692, -27.1507,  15.7907],\n",
              "        [ -8.3220,  -3.9228, -41.8038,  ..., -36.3927,   0.2001,   7.6010],\n",
              "        [-43.0789, -35.1261,  -1.3907,  ...,   7.0581, -39.5310,  10.4448],\n",
              "        ...,\n",
              "        [-23.7399, -24.0462, -36.0432,  ..., -15.2572, -38.3632,  21.3859],\n",
              "        [-67.0633, -36.1652, -26.8833,  ..., -19.6592, -49.6748,  -7.1670],\n",
              "        [-24.0008, -17.5516,  -7.5377,  ..., -11.5033, -35.2708,  35.0855]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tI5u7Ke3lLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output1=activation(torch.mm(input,W1)+B1)\n",
        "output2=activation(torch.mm(output1,W2)+B2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiNLbZDUZ46a",
        "colab_type": "code",
        "outputId": "09c3de89-ac18-4d4f-a08e-f859af708866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9499e-01, 1.3089e-09, 2.2650e-06, 1.0000e+00, 2.1055e-08, 2.9838e-02,\n",
              "         9.9956e-01, 4.5203e-03, 8.7541e-01, 1.2355e-05],\n",
              "        [9.9906e-01, 2.3776e-02, 1.7087e-05, 4.3444e-01, 1.3630e-11, 5.9769e-05,\n",
              "         9.9750e-01, 5.4574e-01, 4.4792e-01, 8.1344e-03],\n",
              "        [1.3998e-01, 5.4940e-04, 2.4144e-09, 9.9618e-01, 1.9940e-05, 2.5512e-04,\n",
              "         9.9987e-01, 7.2119e-03, 2.1626e-01, 2.0508e-08],\n",
              "        [9.0915e-01, 2.7755e-06, 2.6146e-05, 9.8931e-01, 4.9758e-06, 5.3045e-07,\n",
              "         9.9999e-01, 4.8826e-01, 8.8649e-02, 1.2684e-07],\n",
              "        [1.0463e-01, 1.7322e-03, 4.3397e-04, 1.6427e-01, 1.2029e-05, 3.1286e-03,\n",
              "         1.0000e+00, 1.2859e-01, 1.1889e-02, 8.6685e-08],\n",
              "        [9.2699e-01, 8.9814e-01, 1.3578e-04, 1.0000e+00, 3.9503e-05, 5.5698e-04,\n",
              "         9.9690e-01, 5.1047e-03, 1.3020e-05, 2.1753e-09],\n",
              "        [9.1180e-01, 2.0044e-04, 6.3373e-02, 3.4747e-01, 1.5329e-09, 7.7719e-04,\n",
              "         1.0000e+00, 2.7957e-04, 6.5405e-02, 2.9992e-05],\n",
              "        [9.7323e-01, 2.0296e-05, 6.5180e-03, 9.2357e-01, 8.4797e-10, 5.8190e-06,\n",
              "         9.9974e-01, 8.5242e-01, 2.0692e-01, 6.3892e-07],\n",
              "        [9.8670e-01, 4.1110e-03, 4.7928e-05, 9.9962e-01, 3.4286e-04, 2.7467e-03,\n",
              "         9.9904e-01, 3.3196e-03, 6.9634e-04, 4.8162e-05],\n",
              "        [1.0000e+00, 1.4060e-02, 1.8456e-05, 9.9992e-01, 1.0034e-08, 1.7748e-05,\n",
              "         9.9978e-01, 1.8809e-01, 1.7097e-03, 3.9926e-04],\n",
              "        [5.3478e-01, 1.2094e-01, 4.0173e-07, 9.9881e-01, 1.5772e-12, 3.3774e-04,\n",
              "         9.9995e-01, 9.9883e-01, 9.1219e-01, 4.6490e-06],\n",
              "        [9.9486e-01, 1.4872e-02, 2.5046e-02, 9.9998e-01, 2.1621e-06, 4.5321e-03,\n",
              "         7.6587e-01, 5.1544e-02, 4.8044e-02, 3.2248e-05],\n",
              "        [9.9999e-01, 7.9808e-06, 1.0947e-04, 1.0000e+00, 5.8353e-06, 1.6706e-02,\n",
              "         9.9345e-01, 4.0458e-01, 1.4178e-05, 2.2595e-04],\n",
              "        [1.0592e-03, 1.0118e-04, 4.2870e-05, 9.9296e-01, 6.0383e-05, 2.1141e-01,\n",
              "         1.0000e+00, 9.3261e-01, 1.9198e-04, 1.5283e-04],\n",
              "        [8.1769e-01, 1.4331e-01, 2.3223e-05, 2.6351e-04, 3.6778e-04, 1.4134e-01,\n",
              "         9.7059e-01, 9.7078e-01, 9.9886e-01, 1.2634e-05],\n",
              "        [9.9792e-01, 5.6360e-06, 8.4475e-04, 9.9980e-01, 1.4315e-05, 3.2708e-01,\n",
              "         9.9987e-01, 1.6463e-05, 7.9879e-04, 3.3513e-06],\n",
              "        [1.7927e-01, 1.2586e-02, 1.5618e-01, 9.9944e-01, 2.8784e-06, 6.8825e-05,\n",
              "         9.6357e-01, 2.2028e-02, 9.9605e-01, 5.5117e-05],\n",
              "        [9.9996e-01, 9.9573e-08, 1.6226e-05, 9.4550e-01, 2.1936e-07, 7.7068e-04,\n",
              "         9.9950e-01, 9.9968e-01, 1.5754e-05, 9.2759e-04],\n",
              "        [1.8091e-02, 5.3928e-01, 6.0794e-07, 9.9923e-01, 4.3868e-08, 1.8812e-03,\n",
              "         3.7656e-01, 9.9303e-01, 3.8853e-01, 1.0288e-05],\n",
              "        [5.3110e-05, 6.2167e-01, 8.4721e-06, 9.1650e-01, 1.3448e-09, 1.0112e-04,\n",
              "         2.5733e-04, 6.5529e-02, 5.8700e-01, 3.1447e-08],\n",
              "        [9.9593e-01, 8.5195e-06, 2.3769e-04, 9.9991e-01, 4.8274e-07, 1.3754e-05,\n",
              "         9.9686e-01, 7.3372e-01, 1.5230e-04, 1.6072e-05],\n",
              "        [7.9167e-01, 4.0894e-05, 5.1487e-01, 8.9255e-01, 6.6142e-06, 3.5957e-06,\n",
              "         9.9949e-01, 1.0407e-04, 6.6362e-01, 1.0158e-08],\n",
              "        [5.9784e-01, 5.1472e-07, 1.9619e-04, 9.9994e-01, 8.4287e-07, 7.8872e-05,\n",
              "         9.9317e-01, 1.5286e-03, 6.0145e-03, 4.1367e-05],\n",
              "        [9.9994e-01, 7.4640e-01, 9.9170e-01, 1.4054e-01, 2.1602e-09, 2.5768e-07,\n",
              "         9.8162e-01, 2.6603e-05, 3.3979e-01, 4.2551e-09],\n",
              "        [9.0661e-02, 2.8106e-01, 7.4911e-07, 5.0748e-01, 2.9652e-09, 9.2788e-03,\n",
              "         9.9403e-01, 3.0487e-01, 1.8307e-02, 3.0687e-03],\n",
              "        [9.9661e-01, 2.3592e-03, 2.5918e-02, 7.0625e-01, 5.2688e-05, 5.8063e-05,\n",
              "         9.7830e-01, 4.6257e-06, 2.1663e-01, 4.1207e-04],\n",
              "        [7.7534e-01, 9.6510e-03, 5.9446e-06, 1.4747e-02, 1.5016e-06, 2.2883e-02,\n",
              "         1.0000e+00, 7.6803e-03, 5.8824e-05, 1.9223e-03],\n",
              "        [1.0000e+00, 3.8799e-03, 9.0961e-04, 1.0000e+00, 4.6312e-07, 2.7253e-01,\n",
              "         9.9976e-01, 7.4495e-02, 7.5344e-04, 1.7570e-03],\n",
              "        [9.8148e-01, 9.4493e-03, 3.7352e-02, 9.9999e-01, 1.7975e-05, 1.1457e-04,\n",
              "         8.9780e-01, 1.7043e-01, 5.3976e-04, 1.5662e-06],\n",
              "        [9.8509e-01, 9.2597e-07, 1.8411e-07, 1.0000e+00, 1.7737e-05, 1.3498e-04,\n",
              "         9.8827e-01, 6.0465e-02, 7.3612e-01, 2.9232e-04],\n",
              "        [9.9946e-01, 8.2023e-03, 2.8203e-03, 8.3602e-01, 2.7382e-10, 9.4266e-07,\n",
              "         8.3706e-01, 4.5423e-02, 1.0556e-05, 1.7819e-02],\n",
              "        [9.9240e-01, 9.0668e-07, 1.1836e-07, 1.0000e+00, 2.7233e-06, 2.2774e-01,\n",
              "         2.0242e-01, 8.7724e-01, 4.2540e-02, 3.4494e-07],\n",
              "        [7.3240e-01, 6.4101e-06, 3.3025e-07, 9.9990e-01, 2.3346e-06, 4.4153e-02,\n",
              "         9.9998e-01, 2.0959e-02, 1.2638e-02, 1.9071e-06],\n",
              "        [9.9593e-01, 3.2237e-03, 6.1360e-06, 9.9999e-01, 6.0367e-05, 7.4168e-04,\n",
              "         1.0000e+00, 2.8901e-01, 7.1859e-03, 6.5889e-04],\n",
              "        [9.2513e-01, 8.7738e-03, 7.8118e-04, 9.9954e-01, 9.2648e-06, 3.8785e-03,\n",
              "         9.0176e-01, 9.5780e-01, 5.6839e-01, 1.5974e-03],\n",
              "        [4.4045e-04, 1.4165e-06, 3.0536e-04, 8.9349e-01, 2.4979e-09, 1.2603e-06,\n",
              "         9.9908e-01, 1.3296e-02, 9.8973e-01, 2.2954e-06],\n",
              "        [5.8199e-01, 1.0698e-03, 5.3051e-07, 5.1131e-03, 1.7704e-04, 9.7773e-01,\n",
              "         1.0000e+00, 9.2984e-01, 9.3045e-02, 5.1745e-03],\n",
              "        [1.0000e+00, 6.2246e-04, 3.7599e-05, 1.0000e+00, 3.3573e-05, 2.3530e-04,\n",
              "         9.9987e-01, 8.7902e-01, 5.0126e-01, 8.6190e-04],\n",
              "        [1.3601e-01, 8.2643e-05, 6.9689e-01, 6.7785e-02, 1.2757e-06, 3.1731e-06,\n",
              "         9.9164e-01, 3.9314e-04, 5.5341e-02, 4.8241e-05],\n",
              "        [1.2684e-01, 4.4402e-05, 5.1212e-01, 1.0251e-01, 5.9577e-08, 6.9577e-06,\n",
              "         1.0000e+00, 1.8039e-04, 1.7130e-01, 1.9769e-04],\n",
              "        [1.0000e+00, 2.5372e-02, 1.2133e-01, 1.0000e+00, 4.5747e-07, 8.4305e-03,\n",
              "         1.0000e+00, 1.1074e-02, 2.9424e-03, 1.7568e-07],\n",
              "        [9.7933e-01, 1.8103e-04, 6.5239e-04, 9.9293e-01, 2.7586e-06, 1.9325e-07,\n",
              "         1.0000e+00, 1.2854e-01, 5.3595e-01, 5.0016e-06],\n",
              "        [9.9983e-01, 1.4346e-07, 2.1021e-01, 9.9999e-01, 4.2378e-07, 9.4411e-01,\n",
              "         9.9897e-01, 1.6775e-01, 1.3462e-01, 7.8380e-04],\n",
              "        [8.5897e-01, 7.4955e-05, 1.4391e-04, 9.9541e-01, 2.7382e-03, 1.9254e-04,\n",
              "         9.9995e-01, 1.7908e-05, 6.8886e-05, 6.1027e-05],\n",
              "        [9.4954e-01, 1.2694e-03, 2.3396e-08, 9.9999e-01, 9.6962e-01, 6.0678e-04,\n",
              "         3.3421e-02, 9.9998e-01, 3.9150e-02, 2.0209e-01],\n",
              "        [1.0000e+00, 6.0405e-05, 1.9665e-06, 1.0000e+00, 7.1049e-07, 7.9408e-07,\n",
              "         9.9998e-01, 7.7889e-01, 5.6317e-03, 6.8848e-06],\n",
              "        [3.7369e-01, 1.3934e-03, 4.8604e-04, 9.9926e-01, 1.7342e-10, 6.6644e-03,\n",
              "         5.7587e-01, 9.1261e-01, 3.9679e-04, 3.1591e-06],\n",
              "        [9.9736e-01, 1.3801e-05, 9.4665e-01, 8.8896e-01, 9.2757e-08, 2.5845e-05,\n",
              "         9.9998e-01, 7.7849e-01, 9.8737e-01, 2.9235e-08],\n",
              "        [9.7355e-01, 7.9482e-01, 7.4796e-01, 7.5454e-01, 6.4969e-08, 1.2411e-02,\n",
              "         9.6883e-01, 9.5853e-01, 9.4953e-01, 1.0880e-09],\n",
              "        [9.8438e-01, 6.0722e-05, 2.4903e-05, 1.0000e+00, 1.7083e-06, 5.4238e-04,\n",
              "         9.9992e-01, 9.9385e-01, 1.2774e-03, 1.3654e-08],\n",
              "        [9.9430e-01, 1.4969e-05, 5.1055e-03, 9.9999e-01, 2.1579e-06, 7.9192e-05,\n",
              "         9.9853e-01, 1.4842e-03, 4.2231e-03, 1.6999e-07],\n",
              "        [9.9958e-01, 1.7253e-02, 3.8859e-02, 1.0000e+00, 3.4750e-07, 2.2579e-07,\n",
              "         9.9181e-01, 1.7332e-02, 2.6794e-04, 4.4473e-06],\n",
              "        [9.9985e-01, 1.0656e-02, 2.1581e-04, 1.1650e-02, 3.3256e-06, 3.5999e-05,\n",
              "         9.8634e-01, 1.1960e-03, 2.5871e-05, 1.0173e-03],\n",
              "        [4.5481e-02, 2.5983e-03, 3.9112e-05, 2.0516e-03, 6.7459e-07, 1.0562e-01,\n",
              "         9.9999e-01, 9.9634e-03, 9.4969e-01, 4.0435e-01],\n",
              "        [9.9154e-01, 4.2592e-04, 1.0550e-08, 9.9133e-01, 9.7885e-09, 1.1089e-04,\n",
              "         9.9926e-01, 8.7974e-01, 2.3258e-04, 3.5704e-03],\n",
              "        [9.9255e-01, 8.0550e-09, 3.1025e-05, 1.0539e-01, 2.9795e-06, 3.0033e-04,\n",
              "         1.0000e+00, 9.9966e-01, 5.7179e-02, 1.5457e-02],\n",
              "        [9.9134e-01, 8.2417e-02, 6.3299e-04, 9.9999e-01, 7.2206e-06, 5.1015e-04,\n",
              "         9.9999e-01, 8.0663e-02, 4.2687e-01, 5.5045e-07],\n",
              "        [9.3582e-01, 5.1367e-08, 2.7381e-04, 2.7536e-01, 1.2189e-04, 2.8364e-03,\n",
              "         1.2314e-02, 2.8038e-03, 5.7103e-03, 5.1582e-02],\n",
              "        [9.9911e-01, 8.1968e-05, 7.6180e-01, 9.6576e-01, 1.0162e-03, 2.6548e-03,\n",
              "         1.2231e-01, 2.8942e-04, 5.3008e-02, 9.9366e-08],\n",
              "        [9.9824e-01, 2.4704e-05, 4.6049e-05, 1.0000e+00, 7.5307e-09, 1.1346e-03,\n",
              "         2.9452e-02, 9.9970e-01, 6.5131e-03, 1.2722e-06],\n",
              "        [1.0000e+00, 6.0730e-03, 5.9627e-04, 9.9996e-01, 1.7836e-09, 1.2198e-05,\n",
              "         9.9987e-01, 9.9936e-01, 2.3438e-01, 4.1717e-04],\n",
              "        [8.8660e-01, 3.6458e-04, 9.8027e-06, 9.8725e-01, 9.7898e-07, 8.5960e-05,\n",
              "         9.9850e-01, 9.5736e-01, 2.7587e-02, 7.0847e-05],\n",
              "        [9.9998e-01, 4.5930e-04, 6.7163e-05, 1.0000e+00, 1.2308e-05, 4.7611e-08,\n",
              "         1.0000e+00, 5.0006e-01, 3.1911e-02, 2.5977e-06],\n",
              "        [2.4736e-01, 9.1245e-01, 4.2445e-08, 8.6170e-01, 6.7154e-09, 9.4800e-07,\n",
              "         5.7418e-01, 9.9955e-01, 3.5995e-01, 9.0114e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bggXNQNrazrc",
        "colab_type": "code",
        "outputId": "97530293-f156-4861-9f34-7a14d0f1409e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.exp(output2).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cSrp_gta_Ur",
        "colab_type": "code",
        "outputId": "893c286e-69fd-46a4-ddda-25e43e282a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.sum(torch.exp(output2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(987.5542)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V85Noshep_yn",
        "colab_type": "code",
        "outputId": "166573d1-8d57-4d86-c459-abc1ff567f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "torch.sum(torch.exp(output2),dim=0)  #dim=0 sum of a column"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([145.9167,  71.7259,  72.6261, 148.8071,  65.6421,  68.8656, 158.8706,\n",
              "        104.0200,  86.2382,  64.8418])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9dm3bYTbRMY",
        "colab_type": "code",
        "outputId": "0a30cc57-f2fa-46f1-8e38-16f7b0abb3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "torch.sum(torch.exp(output2),dim=1)  #dim=1 sum of a single row "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16.5748, 15.2946, 13.8256, 15.6120, 12.1616, 16.4159, 13.7569, 16.4641,\n",
              "        15.1266, 15.3773, 17.4741, 14.7205, 15.6530, 15.1957, 16.5665, 15.5369,\n",
              "        15.4458, 16.7283, 15.0826, 13.2293, 16.2183, 15.9807, 14.2440, 16.7477,\n",
              "        13.1700, 14.6664, 12.9470, 15.5521, 15.0749, 16.2335, 14.4091, 15.3438,\n",
              "        14.5954, 15.4908, 17.0896, 14.8640, 15.8095, 17.2156, 12.9764, 12.8176,\n",
              "        15.3321, 15.9271, 17.2835, 14.7880, 16.9577, 16.3396, 14.4478, 19.3014,\n",
              "        19.9404, 16.8160, 15.1463, 15.2063, 13.4242, 13.9741, 16.5211, 15.3197,\n",
              "        15.8349, 11.9434, 14.6734, 15.1869, 17.1422, 16.4582, 15.8366, 16.0651])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDATB9h-qUQM",
        "colab_type": "code",
        "outputId": "20d257fc-fb0d-4801-80a4-694c9a93758e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "torch.sum(torch.exp(output2),dim=1).view(-1,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[16.5748],\n",
              "        [15.2946],\n",
              "        [13.8256],\n",
              "        [15.6120],\n",
              "        [12.1616],\n",
              "        [16.4159],\n",
              "        [13.7569],\n",
              "        [16.4641],\n",
              "        [15.1266],\n",
              "        [15.3773],\n",
              "        [17.4741],\n",
              "        [14.7205],\n",
              "        [15.6530],\n",
              "        [15.1957],\n",
              "        [16.5665],\n",
              "        [15.5369],\n",
              "        [15.4458],\n",
              "        [16.7283],\n",
              "        [15.0826],\n",
              "        [13.2293],\n",
              "        [16.2183],\n",
              "        [15.9807],\n",
              "        [14.2440],\n",
              "        [16.7477],\n",
              "        [13.1700],\n",
              "        [14.6664],\n",
              "        [12.9470],\n",
              "        [15.5521],\n",
              "        [15.0749],\n",
              "        [16.2335],\n",
              "        [14.4091],\n",
              "        [15.3438],\n",
              "        [14.5954],\n",
              "        [15.4908],\n",
              "        [17.0896],\n",
              "        [14.8640],\n",
              "        [15.8095],\n",
              "        [17.2156],\n",
              "        [12.9764],\n",
              "        [12.8176],\n",
              "        [15.3321],\n",
              "        [15.9271],\n",
              "        [17.2835],\n",
              "        [14.7880],\n",
              "        [16.9577],\n",
              "        [16.3396],\n",
              "        [14.4478],\n",
              "        [19.3014],\n",
              "        [19.9404],\n",
              "        [16.8160],\n",
              "        [15.1463],\n",
              "        [15.2063],\n",
              "        [13.4242],\n",
              "        [13.9741],\n",
              "        [16.5211],\n",
              "        [15.3197],\n",
              "        [15.8349],\n",
              "        [11.9434],\n",
              "        [14.6734],\n",
              "        [15.1869],\n",
              "        [17.1422],\n",
              "        [16.4582],\n",
              "        [15.8366],\n",
              "        [16.0651]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX_xnwT8n952",
        "colab_type": "code",
        "outputId": "755710af-7c35-4b79-fb89-abed24a07add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.sum(torch.exp(output2),dim=1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKp4M1cW3w5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "  return torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6OMEks2G3Ru",
        "colab_type": "code",
        "outputId": "4dc4cc38-d1af-401f-9f75-c0f8368d0d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "probabilities=softmax(output2)\n",
        "probabilities"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1632, 0.0603, 0.0603, 0.1640, 0.0603, 0.0622, 0.1639, 0.0606, 0.1448,\n",
              "         0.0603],\n",
              "        [0.1776, 0.0670, 0.0654, 0.1010, 0.0654, 0.0654, 0.1773, 0.1128, 0.1023,\n",
              "         0.0659],\n",
              "        [0.0832, 0.0724, 0.0723, 0.1959, 0.0723, 0.0723, 0.1966, 0.0729, 0.0898,\n",
              "         0.0723],\n",
              "        [0.1590, 0.0641, 0.0641, 0.1723, 0.0641, 0.0641, 0.1741, 0.1044, 0.0700,\n",
              "         0.0641],\n",
              "        [0.0913, 0.0824, 0.0823, 0.0969, 0.0822, 0.0825, 0.2235, 0.0935, 0.0832,\n",
              "         0.0822],\n",
              "        [0.1539, 0.1496, 0.0609, 0.1656, 0.0609, 0.0610, 0.1651, 0.0612, 0.0609,\n",
              "         0.0609],\n",
              "        [0.1809, 0.0727, 0.0774, 0.1029, 0.0727, 0.0727, 0.1976, 0.0727, 0.0776,\n",
              "         0.0727],\n",
              "        [0.1607, 0.0607, 0.0611, 0.1530, 0.0607, 0.0607, 0.1651, 0.1425, 0.0747,\n",
              "         0.0607],\n",
              "        [0.1773, 0.0664, 0.0661, 0.1796, 0.0661, 0.0663, 0.1795, 0.0663, 0.0662,\n",
              "         0.0661],\n",
              "        [0.1768, 0.0660, 0.0650, 0.1768, 0.0650, 0.0650, 0.1767, 0.0785, 0.0651,\n",
              "         0.0651],\n",
              "        [0.0977, 0.0646, 0.0572, 0.1554, 0.0572, 0.0572, 0.1556, 0.1554, 0.1425,\n",
              "         0.0572],\n",
              "        [0.1837, 0.0690, 0.0697, 0.1847, 0.0679, 0.0682, 0.1461, 0.0715, 0.0713,\n",
              "         0.0679],\n",
              "        [0.1737, 0.0639, 0.0639, 0.1737, 0.0639, 0.0650, 0.1725, 0.0957, 0.0639,\n",
              "         0.0639],\n",
              "        [0.0659, 0.0658, 0.0658, 0.1776, 0.0658, 0.0813, 0.1789, 0.1672, 0.0658,\n",
              "         0.0658],\n",
              "        [0.1367, 0.0697, 0.0604, 0.0604, 0.0604, 0.0695, 0.1593, 0.1594, 0.1639,\n",
              "         0.0604],\n",
              "        [0.1746, 0.0644, 0.0644, 0.1749, 0.0644, 0.0893, 0.1749, 0.0644, 0.0644,\n",
              "         0.0644],\n",
              "        [0.0775, 0.0656, 0.0757, 0.1759, 0.0647, 0.0647, 0.1697, 0.0662, 0.1753,\n",
              "         0.0647],\n",
              "        [0.1625, 0.0598, 0.0598, 0.1539, 0.0598, 0.0598, 0.1624, 0.1624, 0.0598,\n",
              "         0.0598],\n",
              "        [0.0675, 0.1137, 0.0663, 0.1801, 0.0663, 0.0664, 0.0966, 0.1790, 0.0978,\n",
              "         0.0663],\n",
              "        [0.0756, 0.1408, 0.0756, 0.1890, 0.0756, 0.0756, 0.0756, 0.0807, 0.1360,\n",
              "         0.0756],\n",
              "        [0.1669, 0.0617, 0.0617, 0.1676, 0.0617, 0.0617, 0.1671, 0.1284, 0.0617,\n",
              "         0.0617],\n",
              "        [0.1381, 0.0626, 0.1047, 0.1528, 0.0626, 0.0626, 0.1700, 0.0626, 0.1215,\n",
              "         0.0626],\n",
              "        [0.1276, 0.0702, 0.0702, 0.1908, 0.0702, 0.0702, 0.1895, 0.0703, 0.0706,\n",
              "         0.0702],\n",
              "        [0.1623, 0.1260, 0.1610, 0.0687, 0.0597, 0.0597, 0.1594, 0.0597, 0.0839,\n",
              "         0.0597],\n",
              "        [0.0831, 0.1006, 0.0759, 0.1261, 0.0759, 0.0766, 0.2052, 0.1030, 0.0773,\n",
              "         0.0762],\n",
              "        [0.1847, 0.0683, 0.0700, 0.1382, 0.0682, 0.0682, 0.1814, 0.0682, 0.0847,\n",
              "         0.0682],\n",
              "        [0.1677, 0.0780, 0.0772, 0.0784, 0.0772, 0.0790, 0.2100, 0.0778, 0.0772,\n",
              "         0.0774],\n",
              "        [0.1748, 0.0645, 0.0644, 0.1748, 0.0643, 0.0844, 0.1747, 0.0693, 0.0643,\n",
              "         0.0644],\n",
              "        [0.1770, 0.0670, 0.0689, 0.1803, 0.0663, 0.0663, 0.1628, 0.0787, 0.0664,\n",
              "         0.0663],\n",
              "        [0.1650, 0.0616, 0.0616, 0.1674, 0.0616, 0.0616, 0.1655, 0.0654, 0.1286,\n",
              "         0.0616],\n",
              "        [0.1885, 0.0700, 0.0696, 0.1601, 0.0694, 0.0694, 0.1603, 0.0726, 0.0694,\n",
              "         0.0706],\n",
              "        [0.1758, 0.0652, 0.0652, 0.1772, 0.0652, 0.0818, 0.0798, 0.1567, 0.0680,\n",
              "         0.0652],\n",
              "        [0.1425, 0.0685, 0.0685, 0.1862, 0.0685, 0.0716, 0.1862, 0.0700, 0.0694,\n",
              "         0.0685],\n",
              "        [0.1748, 0.0648, 0.0646, 0.1755, 0.0646, 0.0646, 0.1755, 0.0862, 0.0650,\n",
              "         0.0646],\n",
              "        [0.1476, 0.0590, 0.0586, 0.1590, 0.0585, 0.0587, 0.1442, 0.1525, 0.1033,\n",
              "         0.0586],\n",
              "        [0.0673, 0.0673, 0.0673, 0.1644, 0.0673, 0.0673, 0.1827, 0.0682, 0.1810,\n",
              "         0.0673],\n",
              "        [0.1132, 0.0633, 0.0633, 0.0636, 0.0633, 0.1682, 0.1719, 0.1603, 0.0694,\n",
              "         0.0636],\n",
              "        [0.1579, 0.0581, 0.0581, 0.1579, 0.0581, 0.0581, 0.1579, 0.1399, 0.0959,\n",
              "         0.0581],\n",
              "        [0.0883, 0.0771, 0.1547, 0.0825, 0.0771, 0.0771, 0.2077, 0.0771, 0.0814,\n",
              "         0.0771],\n",
              "        [0.0886, 0.0780, 0.1302, 0.0864, 0.0780, 0.0780, 0.2121, 0.0780, 0.0926,\n",
              "         0.0780],\n",
              "        [0.1773, 0.0669, 0.0736, 0.1773, 0.0652, 0.0658, 0.1773, 0.0659, 0.0654,\n",
              "         0.0652],\n",
              "        [0.1672, 0.0628, 0.0628, 0.1695, 0.0628, 0.0628, 0.1707, 0.0714, 0.1073,\n",
              "         0.0628],\n",
              "        [0.1572, 0.0579, 0.0714, 0.1573, 0.0579, 0.1487, 0.1571, 0.0684, 0.0662,\n",
              "         0.0579],\n",
              "        [0.1596, 0.0676, 0.0676, 0.1830, 0.0678, 0.0676, 0.1838, 0.0676, 0.0676,\n",
              "         0.0676],\n",
              "        [0.1524, 0.0590, 0.0590, 0.1603, 0.1555, 0.0590, 0.0610, 0.1603, 0.0613,\n",
              "         0.0722],\n",
              "        [0.1664, 0.0612, 0.0612, 0.1664, 0.0612, 0.0612, 0.1664, 0.1334, 0.0615,\n",
              "         0.0612],\n",
              "        [0.1006, 0.0693, 0.0692, 0.1880, 0.0692, 0.0697, 0.1231, 0.1724, 0.0692,\n",
              "         0.0692],\n",
              "        [0.1405, 0.0518, 0.1335, 0.1260, 0.0518, 0.0518, 0.1408, 0.1129, 0.1391,\n",
              "         0.0518],\n",
              "        [0.1328, 0.1110, 0.1060, 0.1066, 0.0501, 0.0508, 0.1321, 0.1308, 0.1296,\n",
              "         0.0501],\n",
              "        [0.1591, 0.0595, 0.0595, 0.1616, 0.0595, 0.0595, 0.1616, 0.1607, 0.0595,\n",
              "         0.0595],\n",
              "        [0.1784, 0.0660, 0.0664, 0.1795, 0.0660, 0.0660, 0.1792, 0.0661, 0.0663,\n",
              "         0.0660],\n",
              "        [0.1787, 0.0669, 0.0684, 0.1788, 0.0658, 0.0658, 0.1773, 0.0669, 0.0658,\n",
              "         0.0658],\n",
              "        [0.2025, 0.0753, 0.0745, 0.0754, 0.0745, 0.0745, 0.1997, 0.0746, 0.0745,\n",
              "         0.0746],\n",
              "        [0.0749, 0.0717, 0.0716, 0.0717, 0.0716, 0.0795, 0.1945, 0.0723, 0.1850,\n",
              "         0.1072],\n",
              "        [0.1631, 0.0606, 0.0605, 0.1631, 0.0605, 0.0605, 0.1644, 0.1459, 0.0605,\n",
              "         0.0607],\n",
              "        [0.1761, 0.0653, 0.0653, 0.0725, 0.0653, 0.0653, 0.1774, 0.1774, 0.0691,\n",
              "         0.0663],\n",
              "        [0.1702, 0.0686, 0.0632, 0.1717, 0.0632, 0.0632, 0.1717, 0.0685, 0.0968,\n",
              "         0.0632],\n",
              "        [0.2134, 0.0837, 0.0838, 0.1103, 0.0837, 0.0840, 0.0848, 0.0840, 0.0842,\n",
              "         0.0882],\n",
              "        [0.1851, 0.0682, 0.1460, 0.1790, 0.0682, 0.0683, 0.0770, 0.0682, 0.0719,\n",
              "         0.0682],\n",
              "        [0.1787, 0.0658, 0.0658, 0.1790, 0.0658, 0.0659, 0.0678, 0.1789, 0.0663,\n",
              "         0.0658],\n",
              "        [0.1586, 0.0587, 0.0584, 0.1586, 0.0583, 0.0583, 0.1586, 0.1585, 0.0737,\n",
              "         0.0584],\n",
              "        [0.1475, 0.0608, 0.0608, 0.1631, 0.0608, 0.0608, 0.1649, 0.1583, 0.0625,\n",
              "         0.0608],\n",
              "        [0.1716, 0.0632, 0.0631, 0.1716, 0.0631, 0.0631, 0.1716, 0.1041, 0.0652,\n",
              "         0.0631],\n",
              "        [0.0797, 0.1550, 0.0622, 0.1473, 0.0622, 0.0622, 0.1105, 0.1691, 0.0892,\n",
              "         0.0623]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78Gpy6yhaIln",
        "colab_type": "code",
        "outputId": "dbe83bb2-bec4-4267-98eb-c734d4acabc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs2olK_pRlGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using NN module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDwRdATcrKqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super.__init__()\n",
        "    self.hidden=nn.Linear(784,256)\n",
        "    self.output=nn.Linear(256,10)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    self.softmax=nn.Softmax(dim=1) #Setting dim=1 in nn.Softmax(dim=1) calculates softmax across the columns.\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.hidden(x)\n",
        "    x=self.sigmoid(x)\n",
        "    x=self.output(x)\n",
        "    x=self.softmax(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWep3AQGtRd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super.__init__()\n",
        "    self.hidden=nn.Linear(784,256)\n",
        "    self.output=nn.Linear(256,10)\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.sigmoid(self.hidden)\n",
        "    x=F.softmax(self.output(x),dim=1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYGpwIU6wZrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Defining the layers, 128, 64, 10 units each\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBREldmFxmzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}